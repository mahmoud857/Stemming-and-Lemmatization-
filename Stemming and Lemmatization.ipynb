{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming tranning Code and algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.9.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PorterStemmer algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run >>>>>> run\n",
      "runner >>>>>> runner\n",
      "running >>>>>> run\n",
      "ran >>>>>> ran\n",
      "runs >>>>>> run\n",
      "easily >>>>>> easili\n",
      "fairly >>>>>> fairli\n"
     ]
    }
   ],
   "source": [
    "words = ['run', 'runner', 'running', 'ran', 'runs', 'easily', 'fairly']\n",
    "for word in words:\n",
    "    print(word,\">>>>>>\",p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SnowballStemmer Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "s_stemmer = SnowballStemmer(language=\"english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run >>>>>>>>>>> run\n",
      "runner >>>>>>>>>>> runner\n",
      "running >>>>>>>>>>> run\n",
      "ran >>>>>>>>>>> ran\n",
      "runs >>>>>>>>>>> run\n",
      "easily >>>>>>>>>>> easili\n",
      "fairly >>>>>>>>>>> fair\n"
     ]
    }
   ],
   "source": [
    "words = ['run', 'runner', 'running', 'ran', 'runs', 'easily', 'fairly']\n",
    "for word in words:\n",
    "    print(word,\">>>>>>>>>>>\",s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SnowballStemmer and PorterStemmer are two popular stemming algorithms. \n",
    "compare the results of the two stemming algorithms on the same words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run >>>>>>>>>> run\n",
      "run >>>>>>>>>>> run\n",
      "--------------------------------------\n",
      "runner >>>>>>>>>> runner\n",
      "runner >>>>>>>>>>> runner\n",
      "--------------------------------------\n",
      "running >>>>>>>>>> run\n",
      "running >>>>>>>>>>> run\n",
      "--------------------------------------\n",
      "ran >>>>>>>>>> ran\n",
      "ran >>>>>>>>>>> ran\n",
      "--------------------------------------\n",
      "runs >>>>>>>>>> run\n",
      "runs >>>>>>>>>>> run\n",
      "--------------------------------------\n",
      "easily >>>>>>>>>> easili\n",
      "easily >>>>>>>>>>> easili\n",
      "--------------------------------------\n",
      "fairly >>>>>>>>>> fairli\n",
      "fairly >>>>>>>>>>> fair\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "words=['run', 'runner', 'running', 'ran', 'runs', 'easily', 'fairly']\n",
    "for word in words:\n",
    "    print(word,\">>>>>>>>>>\",p_stemmer.stem(word))\n",
    "    print(word,\">>>>>>>>>>>\",s_stemmer.stem(word))\n",
    "    print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LancasterStemmer Algorithm is the most aggressive stemming algorithm of the bunch. It is known for its speed and aggressive stemming. However, if you are not careful, it might be over-stemming your words. Over-stemming means that it cuts off the prefixes or the suffixes of the words too much, which might result in losing the actual meaning of the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer\n",
    "ps=PorterStemmer()\n",
    "ls=LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word befor stemming << is >> word after stemming << is >>\n",
      "word befor stemming << is >> word after stemming << is >>\n",
      "--------------------------------------\n",
      "word befor stemming << are >> word after stemming << ar >>\n",
      "word befor stemming << are >> word after stemming << are >>\n",
      "--------------------------------------\n",
      "word befor stemming << am >> word after stemming << am >>\n",
      "word befor stemming << am >> word after stemming << am >>\n",
      "--------------------------------------\n",
      "word befor stemming << has >> word after stemming << has >>\n",
      "word befor stemming << has >> word after stemming << ha >>\n",
      "--------------------------------------\n",
      "word befor stemming << have >> word after stemming << hav >>\n",
      "word befor stemming << have >> word after stemming << have >>\n",
      "--------------------------------------\n",
      "word befor stemming << had >> word after stemming << had >>\n",
      "word befor stemming << had >> word after stemming << had >>\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "words=['is', 'are', 'am', 'has', 'have', 'had']\n",
    "for word in words:\n",
    "    print(\"word befor stemming\",\"<<\", word ,\">>\" ,\"word after stemming\",\"<<\",ls.stem(word),\">>\")\n",
    "    print(\"word befor stemming\",\"<<\", word ,\">>\" ,\"word after stemming\",\"<<\",ps.stem(word),\">>\")\n",
    "    print(\"--------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"book\",\"booking\",\"booked\",\"books\",\"booker\",\"bookstore\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word befor stemming << book >> word after stemming << book >>\n",
      "word befor stemming << booking >> word after stemming << book >>\n",
      "word befor stemming << booked >> word after stemming << book >>\n",
      "word befor stemming << books >> word after stemming << book >>\n",
      "word befor stemming << booker >> word after stemming << booker >>\n",
      "word befor stemming << bookstore >> word after stemming << bookstor >>\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(\"word befor stemming\",\"<<\", word ,\">>\" ,\"word after stemming\",\"<<\",ps.stem(word),\">>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of porter stemmer algorithm It's pretty good in this example, but when I applied lancaster stemmer algorithms to this example, the result was a little better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word befor stemming << book >> word after stemming << book >>\n",
      "word befor stemming << booking >> word after stemming << book >>\n",
      "word befor stemming << booked >> word after stemming << book >>\n",
      "word befor stemming << books >> word after stemming << book >>\n",
      "word befor stemming << booker >> word after stemming << book >>\n",
      "word befor stemming << bookstore >> word after stemming << bookst >>\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(\"word befor stemming\",\"<<\", word ,\">>\" ,\"word after stemming\",\"<<\",ls.stem(word),\">>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word befor stemming << book >> word after stemming << book >>\n",
      "word befor stemming << book >> word after stemming << book >>\n",
      "--------------------------------------\n",
      "word befor stemming << booking >> word after stemming << book >>\n",
      "word befor stemming << booking >> word after stemming << book >>\n",
      "--------------------------------------\n",
      "word befor stemming << booked >> word after stemming << book >>\n",
      "word befor stemming << booked >> word after stemming << book >>\n",
      "--------------------------------------\n",
      "word befor stemming << books >> word after stemming << book >>\n",
      "word befor stemming << books >> word after stemming << book >>\n",
      "--------------------------------------\n",
      "word befor stemming << booker >> word after stemming << book >>\n",
      "word befor stemming << booker >> word after stemming << booker >>\n",
      "--------------------------------------\n",
      "word befor stemming << bookstore >> word after stemming << bookst >>\n",
      "word befor stemming << bookstore >> word after stemming << bookstor >>\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(\"word befor stemming\",\"<<\", word ,\">>\" ,\"word after stemming\",\"<<\",ls.stem(word),\">>\")\n",
    "    print(\"word befor stemming\",\"<<\", word ,\">>\" ,\"word after stemming\",\"<<\",ps.stem(word),\">>\")\n",
    "    print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to Deal with sentence for stemming ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer , LancasterStemmer\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'had you booked the air booking yet ? if not try to book it ASAP since booking will be out of books'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=word_tokenize(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word befor stemming << had >> word after stemming << had >>\n",
      "word befor stemming << you >> word after stemming << you >>\n",
      "word befor stemming << booked >> word after stemming << book >>\n",
      "word befor stemming << the >> word after stemming << the >>\n",
      "word befor stemming << air >> word after stemming << air >>\n",
      "word befor stemming << booking >> word after stemming << book >>\n",
      "word befor stemming << yet >> word after stemming << yet >>\n",
      "word befor stemming << ? >> word after stemming << ? >>\n",
      "word befor stemming << if >> word after stemming << if >>\n",
      "word befor stemming << not >> word after stemming << not >>\n",
      "word befor stemming << try >> word after stemming << tri >>\n",
      "word befor stemming << to >> word after stemming << to >>\n",
      "word befor stemming << book >> word after stemming << book >>\n",
      "word befor stemming << it >> word after stemming << it >>\n",
      "word befor stemming << ASAP >> word after stemming << asap >>\n",
      "word befor stemming << since >> word after stemming << sinc >>\n",
      "word befor stemming << booking >> word after stemming << book >>\n",
      "word befor stemming << will >> word after stemming << will >>\n",
      "word befor stemming << be >> word after stemming << be >>\n",
      "word befor stemming << out >> word after stemming << out >>\n",
      "word befor stemming << of >> word after stemming << of >>\n",
      "word befor stemming << books >> word after stemming << book >>\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(\"word befor stemming\",\"<<\", word ,\">>\" ,\"word after stemming\",\"<<\",ps.stem(word),\">>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word befor stemming << had >> word after stemming << had >>\n",
      "word befor stemming << you >> word after stemming << you >>\n",
      "word befor stemming << booked >> word after stemming << book >>\n",
      "word befor stemming << the >> word after stemming << the >>\n",
      "word befor stemming << air >> word after stemming << air >>\n",
      "word befor stemming << booking >> word after stemming << book >>\n",
      "word befor stemming << yet >> word after stemming << yet >>\n",
      "word befor stemming << ? >> word after stemming << ? >>\n",
      "word befor stemming << if >> word after stemming << if >>\n",
      "word befor stemming << not >> word after stemming << not >>\n",
      "word befor stemming << try >> word after stemming << try >>\n",
      "word befor stemming << to >> word after stemming << to >>\n",
      "word befor stemming << book >> word after stemming << book >>\n",
      "word befor stemming << it >> word after stemming << it >>\n",
      "word befor stemming << ASAP >> word after stemming << asap >>\n",
      "word befor stemming << since >> word after stemming << sint >>\n",
      "word befor stemming << booking >> word after stemming << book >>\n",
      "word befor stemming << will >> word after stemming << wil >>\n",
      "word befor stemming << be >> word after stemming << be >>\n",
      "word befor stemming << out >> word after stemming << out >>\n",
      "word befor stemming << of >> word after stemming << of >>\n",
      "word befor stemming << books >> word after stemming << book >>\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(\"word befor stemming\",\"<<\", word ,\">>\" ,\"word after stemming\",\"<<\",ls.stem(word),\">>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************************************************************************************************************************************************************************************************************\n",
    "********************************************************************************************************\n",
    "********************************************************************************************************\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordNetLemmatizer Algorithm for lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word befor stemming << cats >> word after stemming << cat >>\n",
      "word befor stemming << cacti >> word after stemming << cactus >>\n",
      "word befor stemming << radii >> word after stemming << radius >>\n",
      "word befor stemming << feet >> word after stemming << foot >>\n",
      "word befor stemming << speech >> word after stemming << speech >>\n",
      "word befor stemming << runner >> word after stemming << runner >>\n"
     ]
    }
   ],
   "source": [
    "words=[\"cats\",\"cacti\",\"radii\",\"feet\",\"speech\",'runner']\n",
    "for word in words:\n",
    "    print(\"word befor stemming\",\"<<\", word ,\">>\" ,\"word after stemming\",\"<<\",lemmatizer.lemmatize(word),\">>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meet\n",
      "meeting\n"
     ]
    }
   ],
   "source": [
    "print(lemmatizer.lemmatize(\"meeting\",\"v\"))\n",
    "print(lemmatizer.lemmatize(\"meeting\",\"n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word befor lemmatization << is >> word after lemmatization << is >>\n",
      "word befor lemmatization << was >> word after lemmatization << wa >>\n",
      "word befor lemmatization << be >> word after lemmatization << be >>\n",
      "word befor lemmatization << been >> word after lemmatization << been >>\n",
      "word befor lemmatization << are >> word after lemmatization << are >>\n",
      "word befor lemmatization << were >> word after lemmatization << were >>\n"
     ]
    }
   ],
   "source": [
    "words = [\"is\",\"was\",\"be\",\"been\",\"are\",\"were\"]\n",
    "for word in words:\n",
    "    print(\"word befor lemmatization\",\"<<\", word ,\">>\" ,\"word after lemmatization\",\"<<\",lemmatizer.lemmatize(word),\">>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word befor lemmatization << is >> word after lemmatization << be >>\n",
      "word befor lemmatization << was >> word after lemmatization << be >>\n",
      "word befor lemmatization << be >> word after lemmatization << be >>\n",
      "word befor lemmatization << been >> word after lemmatization << be >>\n",
      "word befor lemmatization << are >> word after lemmatization << be >>\n",
      "word befor lemmatization << were >> word after lemmatization << be >>\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(\"word befor lemmatization\",\"<<\", word ,\">>\" ,\"word after lemmatization\",\"<<\",lemmatizer.lemmatize(word, pos=\"v\"),\">>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in WordNetLemmatizer algorithm the result is good when I determine pos like the previous example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He',\n",
       " 'was',\n",
       " 'running',\n",
       " 'and',\n",
       " 'eating',\n",
       " 'at',\n",
       " 'same',\n",
       " 'time',\n",
       " 'He',\n",
       " 'has',\n",
       " 'bad',\n",
       " 'habit',\n",
       " 'of',\n",
       " 'swimming',\n",
       " 'after',\n",
       " 'playing',\n",
       " 'long',\n",
       " 'hours',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Sun']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
    "punktuations = \"?:!.,;\"\n",
    "words=word_tokenize(sentence)\n",
    "for word in words:\n",
    "    if word in punktuations:\n",
    "        words.remove(word)\n",
    "words        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word befor lemmatization << He >> word after lemmatization << He >>\n",
      "word befor lemmatization << He >> word after lemmatization << He >>\n",
      "****************************************************************************************\n",
      "word befor lemmatization << was >> word after lemmatization << wa >>\n",
      "word befor lemmatization << was >> word after lemmatization << be >>\n",
      "****************************************************************************************\n",
      "word befor lemmatization << running >> word after lemmatization << running >>\n",
      "word befor lemmatization << running >> word after lemmatization << run >>\n",
      "****************************************************************************************\n",
      "word befor lemmatization << and >> word after lemmatization << and >>\n",
      "word befor lemmatization << and >> word after lemmatization << and >>\n",
      "****************************************************************************************\n",
      "word befor lemmatization << eating >> word after lemmatization << eating >>\n",
      "word befor lemmatization << eating >> word after lemmatization << eat >>\n",
      "****************************************************************************************\n",
      "word befor lemmatization << at >> word after lemmatization << at >>\n",
      "word befor lemmatization << at >> word after lemmatization << at >>\n",
      "****************************************************************************************\n",
      "word befor lemmatization << same >> word after lemmatization << same >>\n",
      "word befor lemmatization << same >> word after lemmatization << same >>\n",
      "****************************************************************************************\n",
      "word befor lemmatization << time >> word after lemmatization << time >>\n",
      "word befor lemmatization << time >> word after lemmatization << time >>\n",
      "****************************************************************************************\n",
      "word befor lemmatization << He >> word after lemmatization << He >>\n",
      "word befor lemmatization << He >> word after lemmatization << He >>\n",
      "****************************************************************************************\n",
      "word befor lemmatization << has >> word after lemmatization << ha >>\n",
      "word befor lemmatization << has >> word after lemmatization << have >>\n",
      "****************************************************************************************\n",
      "word befor lemmatization << bad >> word after lemmatization << bad >>\n",
      "word befor lemmatization << bad >> word after lemmatization << bad >>\n",
      "****************************************************************************************\n",
      "word befor lemmatization << habit >> word after lemmatization << habit >>\n",
      "word befor lemmatization << habit >> word after lemmatization << habit >>\n",
      "****************************************************************************************\n",
      "word befor lemmatization << of >> word after lemmatization << of >>\n",
      "word befor lemmatization << of >> word after lemmatization << of >>\n",
      "****************************************************************************************\n",
      "word befor lemmatization << swimming >> word after lemmatization << swimming >>\n",
      "word befor lemmatization << swimming >> word after lemmatization << swim >>\n",
      "****************************************************************************************\n",
      "word befor lemmatization << after >> word after lemmatization << after >>\n",
      "word befor lemmatization << after >> word after lemmatization << after >>\n",
      "****************************************************************************************\n",
      "word befor lemmatization << playing >> word after lemmatization << playing >>\n",
      "word befor lemmatization << playing >> word after lemmatization << play >>\n",
      "****************************************************************************************\n",
      "word befor lemmatization << long >> word after lemmatization << long >>\n",
      "word befor lemmatization << long >> word after lemmatization << long >>\n",
      "****************************************************************************************\n",
      "word befor lemmatization << hours >> word after lemmatization << hour >>\n",
      "word befor lemmatization << hours >> word after lemmatization << hours >>\n",
      "****************************************************************************************\n",
      "word befor lemmatization << in >> word after lemmatization << in >>\n",
      "word befor lemmatization << in >> word after lemmatization << in >>\n",
      "****************************************************************************************\n",
      "word befor lemmatization << the >> word after lemmatization << the >>\n",
      "word befor lemmatization << the >> word after lemmatization << the >>\n",
      "****************************************************************************************\n",
      "word befor lemmatization << Sun >> word after lemmatization << Sun >>\n",
      "word befor lemmatization << Sun >> word after lemmatization << Sun >>\n",
      "****************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(\"word befor lemmatization\",\"<<\", word ,\">>\" ,\"word after lemmatization\",\"<<\",lemmatizer.lemmatize(word),\">>\")\n",
    "    print(\"word befor lemmatization\",\"<<\", word ,\">>\" ,\"word after lemmatization\",\"<<\",lemmatizer.lemmatize(word, pos=\"v\"),\">>\")\n",
    "    print(\"****************************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
